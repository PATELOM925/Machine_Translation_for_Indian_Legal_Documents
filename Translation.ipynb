{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ud7ONYsjbnmq"
      },
      "outputs": [],
      "source": [
        "#Make imports\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import os\n",
        "import seaborn as sns\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install englisttohindi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGY2EO85esMd",
        "outputId": "206c2557-1d4e-4e7d-8a84-924f0a08f56a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting englisttohindi\n",
            "  Downloading englisttohindi-4.1.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from englisttohindi) (2.2.2)\n",
            "Collecting bs4 (from englisttohindi)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from englisttohindi) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->englisttohindi) (4.12.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->englisttohindi) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->englisttohindi) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->englisttohindi) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->englisttohindi) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->englisttohindi) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->englisttohindi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->englisttohindi) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->englisttohindi) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->englisttohindi) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->englisttohindi) (2.6)\n",
            "Downloading englisttohindi-4.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4, englisttohindi\n",
            "Successfully installed bs4-0.0.2 englisttohindi-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from englisttohindi.englisttohindi import EngtoHindi\n",
        "trans = EngtoHindi(message=\"Hello  Everyone  \")\n",
        "print(trans.convert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZMNntsNeuQU",
        "outputId": "49cde1eb-42e9-4ccb-d294-eb436f48a88f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "सभी को नमस्कार\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  text = ''.join(ch for ch in text if ch not in string.punctuation)\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'\\d','',text)\n",
        "  text = re.sub(r'\\s+',' ',text)\n",
        "  text = text.strip()\n",
        "  return text"
      ],
      "metadata": {
        "id": "OM4zPgr1b4Be"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract dataset and preprocess\n",
        "dataset_root = \"/content/\"\n",
        "\n",
        "if os.path.exists(dataset_root + \"preprocessed_data.pickle\"):\n",
        "  with open(dataset_root + \"preprocessed_data.pickle\", 'rb') as f:\n",
        "    english_sentences, hindi_sentences = pickle.load(f)\n",
        "else:\n",
        "  if not os.path.exists(dataset_root + \"IITB.en-hi.en\"):\n",
        "    os.system(\"tar -xzf \" + dataset_root + \"parallel.tgz -C \" + dataset_root)\n",
        "\n",
        "  with open(dataset_root + \"IITB.en-hi.en\",'r') as f:\n",
        "    english_sentences = f.read().split('\\n')\n",
        "\n",
        "  with open(dataset_root + \"IITB.en-hi.hi\",'r', encoding='utf-8') as f:\n",
        "    hindi_sentences = f.read().split('\\n')\n",
        "\n",
        "  english_sentences = [preprocess(en) for en in english_sentences]\n",
        "  hindi_sentences = ['<START> ' + re.sub('[a-zA-Z]','',preprocess(hi)) + ' <END>' for hi in hindi_sentences]\n",
        "\n",
        "  #Remove duplicate sentences\n",
        "  english_unique = set()\n",
        "  english_sentences_temp = []\n",
        "  hindi_sentences_temp = []\n",
        "  #Use the minimum length to avoid IndexError\n",
        "  l = min(len(english_sentences), len(hindi_sentences)) #Changed to use minimum length\n",
        "  for i in range(l):\n",
        "    if english_sentences[i] not in english_unique:\n",
        "      english_unique.add(english_sentences[i])\n",
        "      english_sentences_temp.append(english_sentences[i])\n",
        "      hindi_sentences_temp.append(hindi_sentences[i])\n",
        "\n",
        "  english_sentences = english_sentences_temp\n",
        "  hindi_sentences = hindi_sentences_temp\n",
        "\n",
        "  with open(dataset_root + \"preprocessed_data.pickle\",'wb') as f:\n",
        "    pickle.dump((english_sentences, hindi_sentences), f)"
      ],
      "metadata": {
        "id": "W-QLw56eb5Sc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(english_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SznP6Wg_H1dT",
        "outputId": "991023cd-0907-4574-96d5-6768cf47c9ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "541472"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(hindi_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNixN023PEa0",
        "outputId": "02a07751-66f0-4326-95d9-cffa6ca6230a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36764"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FQooOtV1OlVU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('output_data.json', 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract answers and translated_answers into separate lists\n",
        "answers = data[\"answers\"]\n",
        "translated_answers = data[\"translated_answers\"]"
      ],
      "metadata": {
        "id": "iBQaW8edOk9_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOM4_slqOwkr",
        "outputId": "d69b4c0b-216e-45a2-e65a-e6719142bfb2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4082"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(translated_answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZetoVTrOk2M",
        "outputId": "f8634755-1f4d-4c01-f7c0-e67e82276643"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4082"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences = english_sentences + answers\n",
        "hindi_sentences = hindi_sentences + translated_answers"
      ],
      "metadata": {
        "id": "VhzflqL7PIqw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(english_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbZfUnb0PPeQ",
        "outputId": "63e067d8-846a-4c96-bb9f-b8c106f0b67e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "545554"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences[6011]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kseOuTNnPalO",
        "outputId": "c59a21e2-685e-4809-efc4-e112b9a38cd6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bug buddy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_sentences[6011]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8_fS6ptXPiWv",
        "outputId": "3727708a-6841-4c56-d851-7e6d52f7a098"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<START> बग बड्डी <END>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KqBNqUdjO2f_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(english_sentences), len(hindi_sentences))\n",
        "print()\n",
        "english_sentences[:3], hindi_sentences[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snpeotzsb7X9",
        "outputId": "9f6f0236-5c20-4290-8001-25328e9b23ae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "545554 545554\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['give your application an accessibility workout',\n",
              "  'accerciser accessibility explorer',\n",
              "  'the default plugin layout for the bottom panel'],\n",
              " ['<START> अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें <END>',\n",
              "  '<START> एक्सेर्साइसर पहुंचनीयता अन्वेषक <END>',\n",
              "  '<START> निचले पटल के लिए डिफोल्ट प्लगइन खाका <END>'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Some parameters\n",
        "vocab_size = 10000\n",
        "total_sentences = 25000\n",
        "maxlen = 10\n",
        "epochs = 70\n",
        "validation_split = 0.05"
      ],
      "metadata": {
        "id": "kFAHB4qFb98z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_data = []\n",
        "hi_data = []\n",
        "\n",
        "cnt = 0\n",
        "\n",
        "for (en,hi) in zip(english_sentences, hindi_sentences):\n",
        "  l = min(len(en.split()), len(hi.split()))\n",
        "  if l <= maxlen:\n",
        "    en_data.append(en)\n",
        "    hi_data.append(hi)\n",
        "    cnt += 1\n",
        "  if cnt == total_sentences:\n",
        "    break"
      ],
      "metadata": {
        "id": "H5qxvsh-b_EN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#Tokenize the texts and convert to sequences\n",
        "en_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<OOV>', lower=False)\n",
        "en_tokenizer.fit_on_texts(en_data)\n",
        "en_sequences = en_tokenizer.texts_to_sequences(en_data)\n",
        "\n",
        "hi_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<OOV>', lower=False)\n",
        "hi_tokenizer.fit_on_texts(hi_data)\n",
        "hi_sequences = hi_tokenizer.texts_to_sequences(hi_data)\n",
        "\n",
        "english_vocab_size = len(en_tokenizer.word_index) + 1\n",
        "hindi_vocab_size = len(hi_tokenizer.word_index) + 1\n",
        "print(\"English Vocab Size: \", english_vocab_size)\n",
        "print(\"Hindi Vocab Size: \", hindi_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8vheJ0IcAdM",
        "outputId": "ea167625-4076-4d15-cf2e-8bbb4df20803"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocab Size:  8020\n",
            "Hindi Vocab Size:  9395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare encoder data\n",
        "encoder_inputs = tf.keras.preprocessing.sequence.pad_sequences(en_sequences, maxlen=maxlen, padding='post')"
      ],
      "metadata": {
        "id": "ezt2jjAgcBxA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare decoder data\n",
        "decoder_inputs = []\n",
        "decoder_outputs = []\n",
        "\n",
        "for hi in hi_sequences:\n",
        "  decoder_inputs.append(hi[:-1])\n",
        "  decoder_outputs.append(hi[1:])\n",
        "\n",
        "decoder_inputs = tf.keras.preprocessing.sequence.pad_sequences(decoder_inputs, maxlen=maxlen, padding='post')\n",
        "decoder_outputs = tf.keras.preprocessing.sequence.pad_sequences(decoder_outputs, maxlen=maxlen, padding='post')"
      ],
      "metadata": {
        "id": "9BBJaE1PcD72"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Testing split\n",
        "# 95%, 5%\n",
        "split = int(0.95 * total_sentences)\n",
        "\n",
        "X_train = [encoder_inputs[:split], decoder_inputs[:split]]\n",
        "y_train = decoder_outputs[:split]\n",
        "\n",
        "# Test data to evaluate our NMT model using BLEU score\n",
        "X_test = en_data[:split]\n",
        "y_test = hi_data[:split]\n",
        "\n",
        "print(X_train[0].shape, X_train[1].shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvDOUOYBcFHv",
        "outputId": "d1893465-fcef-407f-fdcf-5d325bda08e1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23750, 10) (23750, 10) (23750, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define LSTM model\n",
        "d_model = 256\n",
        "\n",
        "#Encoder\n",
        "inputs = tf.keras.layers.Input(shape=(None,))\n",
        "x = tf.keras.layers.Embedding(english_vocab_size, d_model, mask_zero=True)(inputs)\n",
        "_,state_h,state_c = tf.keras.layers.LSTM(d_model,activation='relu',return_state=True)(x)\n",
        "\n",
        "#Decoder\n",
        "targets = tf.keras.layers.Input(shape=(None,))\n",
        "embedding_layer = tf.keras.layers.Embedding(hindi_vocab_size, d_model, mask_zero=True)\n",
        "x = embedding_layer(targets)\n",
        "decoder_lstm = tf.keras.layers.LSTM(d_model,activation='relu',return_sequences=True, return_state=True)\n",
        "x,_,_ = decoder_lstm(x, initial_state=[state_h, state_c])\n",
        "dense1 = tf.keras.layers.Dense(hindi_vocab_size, activation='softmax')\n",
        "x = dense1(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=[inputs, targets],outputs=x)\n",
        "model.summary()\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "model.compile(optimizer='rmsprop', loss=loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "E0kTeII_cH52",
        "outputId": "3df2a47c-4d5c-4a80-bdfe-6b5af7f1e3b0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m2,053,120\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_2 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m2,405,120\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │        \u001b[38;5;34m525,312\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]     │                │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),    │        \u001b[38;5;34m525,312\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],          │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9395\u001b[0m)     │      \u001b[38;5;34m2,414,515\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,053,120</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,405,120</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]     │                │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],          │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9395</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,414,515</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,923,379\u001b[0m (30.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,923,379</span> (30.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,923,379\u001b[0m (30.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,923,379</span> (30.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save model after each epoch\n",
        "save_model_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/en2hi.keras',\n",
        "    monitor='val_accuracy',\n",
        "    mode='max'\n",
        ")"
      ],
      "metadata": {
        "id": "WexyilWGcJZ6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=epochs, validation_split=validation_split, callbacks=[save_model_callback, tf.keras.callbacks.TerminateOnNaN()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLnP16L7cLic",
        "outputId": "71d3b609-042f-47b1-913a-c40ba87ef783"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.1012 - loss: 6.6504 - val_accuracy: 0.1068 - val_loss: 5.8181\n",
            "Epoch 2/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.1239 - loss: 5.2551 - val_accuracy: 0.1151 - val_loss: 5.6502\n",
            "Epoch 3/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.1446 - loss: 4.8547 - val_accuracy: 0.1236 - val_loss: 5.4861\n",
            "Epoch 4/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.1596 - loss: 4.5557 - val_accuracy: 0.1263 - val_loss: 5.4402\n",
            "Epoch 5/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.1735 - loss: 4.2885 - val_accuracy: 0.1323 - val_loss: 5.5474\n",
            "Epoch 6/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.1889 - loss: 4.0352 - val_accuracy: 0.1349 - val_loss: 5.3658\n",
            "Epoch 7/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2032 - loss: 3.7955 - val_accuracy: 0.1375 - val_loss: 5.4573\n",
            "Epoch 8/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2146 - loss: 3.6123 - val_accuracy: 0.1416 - val_loss: 5.3350\n",
            "Epoch 9/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2284 - loss: 3.4069 - val_accuracy: 0.1437 - val_loss: 5.3642\n",
            "Epoch 10/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.2371 - loss: 3.2254 - val_accuracy: 0.1397 - val_loss: 5.7733\n",
            "Epoch 11/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2486 - loss: 3.0450 - val_accuracy: 0.1430 - val_loss: 5.4780\n",
            "Epoch 12/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.2609 - loss: 2.8755 - val_accuracy: 0.1447 - val_loss: 5.4805\n",
            "Epoch 13/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.2709 - loss: 2.7225 - val_accuracy: 0.1425 - val_loss: 5.6963\n",
            "Epoch 14/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2804 - loss: 2.5756 - val_accuracy: 0.1406 - val_loss: 5.9070\n",
            "Epoch 15/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.2900 - loss: 2.4310 - val_accuracy: 0.1451 - val_loss: 6.1384\n",
            "Epoch 16/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2979 - loss: 2.3054 - val_accuracy: 0.1429 - val_loss: 6.9493\n",
            "Epoch 17/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3056 - loss: 2.1848 - val_accuracy: 0.1315 - val_loss: 6.5927\n",
            "Epoch 18/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.3141 - loss: 2.0741 - val_accuracy: 0.1372 - val_loss: 6.6232\n",
            "Epoch 19/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.3220 - loss: 1.9396 - val_accuracy: 0.1428 - val_loss: 6.6435\n",
            "Epoch 20/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3303 - loss: 1.8432 - val_accuracy: 0.1422 - val_loss: 7.1614\n",
            "Epoch 21/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3349 - loss: 1.7578 - val_accuracy: 0.1393 - val_loss: 7.1152\n",
            "Epoch 22/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.3429 - loss: 1.6691 - val_accuracy: 0.1412 - val_loss: 8.0636\n",
            "Epoch 23/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3481 - loss: 1.5723 - val_accuracy: 0.1357 - val_loss: 8.8680\n",
            "Epoch 24/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3561 - loss: 1.5001 - val_accuracy: 0.1373 - val_loss: 7.6674\n",
            "Epoch 25/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3621 - loss: 1.4305 - val_accuracy: 0.1389 - val_loss: 7.9577\n",
            "Epoch 26/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.3697 - loss: 1.3322 - val_accuracy: 0.1374 - val_loss: 8.3511\n",
            "Epoch 27/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3756 - loss: 1.2790 - val_accuracy: 0.1409 - val_loss: 8.5717\n",
            "Epoch 28/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.3809 - loss: 1.2234 - val_accuracy: 0.1370 - val_loss: 8.5335\n",
            "Epoch 29/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3843 - loss: 1.2927 - val_accuracy: 0.1285 - val_loss: 8.7909\n",
            "Epoch 30/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3874 - loss: 1.0982 - val_accuracy: 0.1380 - val_loss: 9.3187\n",
            "Epoch 31/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.3899 - loss: 1.0699 - val_accuracy: 0.1328 - val_loss: 9.2215\n",
            "Epoch 32/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3953 - loss: 0.9916 - val_accuracy: 0.1332 - val_loss: 9.5865\n",
            "Epoch 33/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4042 - loss: 0.9550 - val_accuracy: 0.1251 - val_loss: 10.5003\n",
            "Epoch 34/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4051 - loss: 0.9133 - val_accuracy: 0.1370 - val_loss: 10.0808\n",
            "Epoch 35/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4109 - loss: 0.8540 - val_accuracy: 0.1350 - val_loss: 10.4312\n",
            "Epoch 36/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4136 - loss: 0.8216 - val_accuracy: 0.1317 - val_loss: 10.7394\n",
            "Epoch 37/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4188 - loss: 0.7888 - val_accuracy: 0.1344 - val_loss: 10.5017\n",
            "Epoch 38/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4209 - loss: 0.7434 - val_accuracy: 0.1297 - val_loss: 11.6300\n",
            "Epoch 39/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.4235 - loss: 0.7339 - val_accuracy: 0.1311 - val_loss: 11.4312\n",
            "Epoch 40/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4238 - loss: 0.7075 - val_accuracy: 0.1332 - val_loss: 11.2010\n",
            "Epoch 41/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4283 - loss: 0.6648 - val_accuracy: 0.1322 - val_loss: 11.5843\n",
            "Epoch 42/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4307 - loss: 0.6544 - val_accuracy: 0.1315 - val_loss: 12.0377\n",
            "Epoch 43/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4302 - loss: 0.6277 - val_accuracy: 0.1262 - val_loss: 11.7576\n",
            "Epoch 44/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4350 - loss: 0.6135 - val_accuracy: 0.1279 - val_loss: 11.4990\n",
            "Epoch 45/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4330 - loss: 0.6049 - val_accuracy: 0.1318 - val_loss: 13.6930\n",
            "Epoch 46/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4357 - loss: 0.5859 - val_accuracy: 0.1320 - val_loss: 12.1673\n",
            "Epoch 47/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4395 - loss: 0.5568 - val_accuracy: 0.1299 - val_loss: 13.6181\n",
            "Epoch 48/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.4413 - loss: 0.5523 - val_accuracy: 0.1301 - val_loss: 13.4619\n",
            "Epoch 49/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4406 - loss: 0.5286 - val_accuracy: 0.1287 - val_loss: 12.7283\n",
            "Epoch 50/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4384 - loss: 0.5124 - val_accuracy: 0.1276 - val_loss: 12.6425\n",
            "Epoch 51/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4419 - loss: 0.5117 - val_accuracy: 0.1311 - val_loss: 12.9151\n",
            "Epoch 52/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4420 - loss: 0.4931 - val_accuracy: 0.1269 - val_loss: 12.9210\n",
            "Epoch 53/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4462 - loss: 0.4835 - val_accuracy: 0.1307 - val_loss: 13.7020\n",
            "Epoch 54/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4439 - loss: 0.4856 - val_accuracy: 0.1280 - val_loss: 15.0480\n",
            "Epoch 55/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4460 - loss: 0.4771 - val_accuracy: 0.1294 - val_loss: 13.5192\n",
            "Epoch 56/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4482 - loss: 0.4627 - val_accuracy: 0.1295 - val_loss: 13.8491\n",
            "Epoch 57/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4477 - loss: 0.4586 - val_accuracy: 0.1218 - val_loss: 13.6111\n",
            "Epoch 58/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4474 - loss: 0.4479 - val_accuracy: 0.1295 - val_loss: 13.9735\n",
            "Epoch 59/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.4480 - loss: 0.4385 - val_accuracy: 0.1259 - val_loss: 13.5584\n",
            "Epoch 60/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4506 - loss: 0.4106 - val_accuracy: 0.1217 - val_loss: 15.4965\n",
            "Epoch 61/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4510 - loss: 0.4541 - val_accuracy: 0.1260 - val_loss: 13.3900\n",
            "Epoch 62/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.4533 - loss: 0.4318 - val_accuracy: 0.1290 - val_loss: 14.8095\n",
            "Epoch 63/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4539 - loss: 0.3861 - val_accuracy: 0.1305 - val_loss: 14.5628\n",
            "Epoch 64/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4549 - loss: 0.3929 - val_accuracy: 0.1272 - val_loss: 14.1479\n",
            "Epoch 65/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4539 - loss: 0.3911 - val_accuracy: 0.1259 - val_loss: 14.1318\n",
            "Epoch 66/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.4542 - loss: 0.3711 - val_accuracy: 0.1267 - val_loss: 14.9733\n",
            "Epoch 67/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.4526 - loss: 0.3700 - val_accuracy: 0.1220 - val_loss: 14.3930\n",
            "Epoch 68/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.4530 - loss: 0.3786 - val_accuracy: 0.1267 - val_loss: 14.6586\n",
            "Epoch 69/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.4525 - loss: 0.3664 - val_accuracy: 0.1259 - val_loss: 14.3820\n",
            "Epoch 70/70\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4542 - loss: 0.3541 - val_accuracy: 0.1244 - val_loss: 15.0200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ce3210c6710>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrieve previously saved stuff\n",
        "saved_model = tf.keras.models.load_model('/content/en2hi.keras')\n",
        "saved_model.summary()\n",
        "\n",
        "inputs = saved_model.get_layer('input_layer').output\n",
        "_,state_h,state_c = saved_model.get_layer('lstm').output\n",
        "targets = saved_model.get_layer('input_layer_1').output\n",
        "embedding_layer = saved_model.get_layer('embedding_1')\n",
        "decoder_lstm = saved_model.get_layer('lstm_1')\n",
        "dense1 = saved_model.get_layer('dense')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "rxyegE6KcN3I",
        "outputId": "d87324a2-ff6e-4c3c-a714-250285b10bd8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m2,053,120\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_2 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m2,405,120\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │        \u001b[38;5;34m525,312\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]     │                │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),    │        \u001b[38;5;34m525,312\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],          │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9395\u001b[0m)     │      \u001b[38;5;34m2,414,515\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,053,120</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,405,120</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]     │                │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],          │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9395</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,414,515</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,846,760\u001b[0m (60.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,846,760</span> (60.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,923,379\u001b[0m (30.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,923,379</span> (30.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m7,923,381\u001b[0m (30.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,923,381</span> (30.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No such layer: input_layer. Existing layers are: ['input_layer_2', 'input_layer_3', 'embedding_2', 'embedding_3', 'lstm_2', 'lstm_3', 'dense_1'].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-03ac054f00f8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_layer_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    209\u001b[0m                 \u001b[0;34mf\"No such layer: {name}. Existing layers are: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0;34mf\"{list(layer.name for layer in self.layers)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No such layer: input_layer. Existing layers are: ['input_layer_2', 'input_layer_3', 'embedding_2', 'embedding_3', 'lstm_2', 'lstm_3', 'dense_1']."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Inference Model\n",
        "#Encoder\n",
        "encoder = tf.keras.models.Model(inputs, [state_h, state_c])\n",
        "\n",
        "#Decoder\n",
        "decoder_input_h = tf.keras.layers.Input(shape=(d_model,))\n",
        "decoder_input_c = tf.keras.layers.Input(shape=(d_model,))\n",
        "x = embedding_layer(targets)\n",
        "x, decoder_output_h, decoder_output_c = decoder_lstm(x, initial_state=[decoder_input_h, decoder_input_c])\n",
        "x = dense1(x)\n",
        "decoder = tf.keras.models.Model([targets] + [decoder_input_h, decoder_input_c],[x] + [decoder_output_h, decoder_output_c])"
      ],
      "metadata": {
        "id": "3FLV62AxcR4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_sentence(en_input):\n",
        "    # Convert input to numpy array\n",
        "    input_seq = np.array(en_tokenizer.texts_to_sequences([en_input]))\n",
        "\n",
        "    # Predict the initial hidden and cell states for the encoder\n",
        "    next_h, next_c = encoder.predict(input_seq)\n",
        "\n",
        "    # Prepare the first token as the <START> token with correct shape\n",
        "    curr_token = np.zeros((1, 1))  # Reshape to (1, 1) for (batch_size, sequence_length)\n",
        "    curr_token[0, 0] = hi_tokenizer.word_index['<START>']\n",
        "\n",
        "    pred_sentence = ''\n",
        "\n",
        "    for i in range(maxlen):\n",
        "        # Predict the next word\n",
        "        output, next_h, next_c = decoder.predict([curr_token, next_h, next_c])\n",
        "\n",
        "        # Get the token with the highest probability\n",
        "        next_token = np.argmax(output[0, 0, :])\n",
        "        next_word = hi_tokenizer.index_word[next_token]\n",
        "\n",
        "        # Check for the <END> token\n",
        "        if next_word == '<END>':\n",
        "            break\n",
        "        else:\n",
        "            pred_sentence += ' ' + next_word\n",
        "            curr_token[0, 0] = next_token  # Update curr_token with correct shape\n",
        "\n",
        "    return pred_sentence\n"
      ],
      "metadata": {
        "id": "TTjktuVhcTag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing and Analysis\n",
        "import nltk\n",
        "\n",
        "candidates = []\n",
        "references = []\n",
        "\n",
        "ctr = 20\n",
        "i = 0\n",
        "\n",
        "while ctr>0:\n",
        "  l = len(X_test[i].split())\n",
        "  if l<=maxlen:   #Choose only sentences of length in range [5,15]\n",
        "    pred_sentence = predict_sentence(X_test[i])\n",
        "    candidates.append(pred_sentence.split())\n",
        "\n",
        "    print(\"Input: \", X_test[i])\n",
        "    print(\"Prediction: \", pred_sentence)\n",
        "\n",
        "    trans = EngtoHindi(message=X_test[i])\n",
        "    python_translated_sentence = trans.convert\n",
        "\n",
        "    print(\"Google Translated Reference: \", python_translated_sentence)\n",
        "    print(\"Dataset Reference: \", ' '.join(y_test[i].split()[1:-1]))\n",
        "    print()\n",
        "    references.append([y_test[i].split()[1:-1], python_translated_sentence.split()])\n",
        "\n",
        "    ctr -= 1\n",
        "  i += 1\n",
        "\n",
        "print(nltk.translate.bleu_score.corpus_bleu(references, candidates))"
      ],
      "metadata": {
        "id": "wOLGypD6cVyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g1IWRKzTe2II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_sentence(en_input):\n",
        "    # Step 1: Convert input text to sequence using the English tokenizer\n",
        "    input_seq = np.array(en_tokenizer.texts_to_sequences([en_input]))\n",
        "\n",
        "    # Step 2: Predict encoder hidden and cell states\n",
        "    next_h, next_c = encoder.predict(input_seq)\n",
        "\n",
        "    # Step 3: Initialize the first token as <START> for the decoder\n",
        "    curr_token = np.zeros((1, 1))  # Shape: (batch_size, sequence_length)\n",
        "    curr_token[0, 0] = hi_tokenizer.word_index.get('<START>', 1)  # Default to 1 if <START> not found\n",
        "\n",
        "    pred_sentence = ''\n",
        "\n",
        "    for _ in range(maxlen):\n",
        "        # Step 4: Predict the next word\n",
        "        output, next_h, next_c = decoder.predict([curr_token, next_h, next_c])\n",
        "\n",
        "        # Step 5: Identify the word with the highest probability\n",
        "        next_token = np.argmax(output[0, 0, :])\n",
        "        next_word = hi_tokenizer.index_word.get(next_token, '')\n",
        "\n",
        "        # Step 6: Check for <END> token to stop the translation\n",
        "        if next_word == '<END>':\n",
        "            break\n",
        "        else:\n",
        "            pred_sentence += ' ' + next_word\n",
        "            curr_token[0, 0] = next_token  # Update current token for next prediction\n",
        "\n",
        "    return pred_sentence.strip()\n"
      ],
      "metadata": {
        "id": "c504A_mIhGxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = input(\"Enter an English sentence to translate to Hindi: \")\n",
        "preprocessed_input = preprocess(user_input)  # Preprocess input\n",
        "translated_sentence = predict_sentence(preprocessed_input)\n",
        "print(\"Translated Hindi sentence:\", translated_sentence)"
      ],
      "metadata": {
        "id": "a2--1xPte5_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#install transformers library\n",
        "!pip install transformers -U -q\n",
        "\n",
        "# install sentencepiece library\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "Cc7D_CxSe52d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "yFWl_PMal8ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "\n",
        "# download and save model\n",
        "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n",
        "# import tokenizer\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")\n"
      ],
      "metadata": {
        "id": "zN8gAKTpe5z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2oyyOY49jIjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_to_hindi(text):\n",
        "    \"\"\"\n",
        "    Translates an English text input to Hindi.\n",
        "\n",
        "    Args:\n",
        "    text (str): The English text to be translated.\n",
        "\n",
        "    Returns:\n",
        "    str: The translated text in Hindi.\n",
        "    \"\"\"\n",
        "    # Convert the input text to tensors\n",
        "    model_inputs = tokenizer([text], return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Translate from English to Hindi\n",
        "    generated_tokens = model.generate(\n",
        "        **model_inputs,\n",
        "        forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"]\n",
        "    )\n",
        "\n",
        "    # Decode the generated tokens to get the Hindi translation\n",
        "    translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    return translation[0]\n",
        "\n",
        "# Example usage\n",
        "user_text = input(\"Enter a sentence in English to translate to Hindi: \")\n",
        "\n",
        "trans = EngtoHindi(message=user_text)\n",
        "print(\"Translation in Hindi:\", translate_to_hindi(user_text))\n",
        "\n",
        "python_translated_sentence = trans.convert\n",
        "print(\"Python Translated Reference: \", python_translated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTLXySt-jI9M",
        "outputId": "2963d507-e441-4c90-82e3-d1fcb69bb80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence in English to translate to Hindi: The (the criminal act of deliberately setting fire to property.) led to extensive (the name for anything which can be owned.) damage .<n>The defendant 's legal team argued for an (the court's decision that a person is innocent of the crime they were charged with\n",
            "Translation in Hindi: प्रतिवादी के कानूनी दल ने एक (न्यायालय के निर्णय के लिए तर्क दिया कि एक व्यक्ति उन अपराधों से निर्दोष है जिन पर वे आरोपित थे\n",
            "Python Translated Reference:  (जानबूझकर संपत्ति में आग लगाने का आपराधिक कृत्य) से व्यापक क्षति हुई (किसी भी चीज़ का नाम जिसका स्वामित्व हो सकता है।) प्रतिवादी की कानूनी टीम ने अदालत के फैसले के लिए तर्क दिया कि एक व्यक्ति निर्दोष है \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.tokenize import word_tokenize\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "\n",
        "def translate_to_hindi(text):\n",
        "    \"\"\"\n",
        "    Translates an English text input to Hindi.\n",
        "\n",
        "    Args:\n",
        "    text (str): The English text to be translated.\n",
        "\n",
        "    Returns:\n",
        "    str: The translated text in Hindi.\n",
        "    \"\"\"\n",
        "    # Convert the input text to tensors\n",
        "    model_inputs = tokenizer([text], return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Translate from English to Hindi\n",
        "    generated_tokens = model.generate(\n",
        "        **model_inputs,\n",
        "        forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"]\n",
        "    )\n",
        "\n",
        "    # Decode the generated tokens to get the Hindi translation\n",
        "    translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    return translation[0]\n",
        "\n",
        "# Example usage\n",
        "user_text = input(\"Enter a sentence in English to translate to Hindi: \")\n",
        "generated_translation = translate_to_hindi(user_text)\n",
        "\n",
        "# Assuming `python_translated_sentence` is the reference translation from EngtoHindi library\n",
        "trans = EngtoHindi(message=user_text)\n",
        "python_translated_sentence = trans.convert  # Reference translation\n",
        "\n",
        "# Tokenize the generated and reference translations\n",
        "generated_tokens = word_tokenize(generated_translation)\n",
        "reference_tokens = word_tokenize(python_translated_sentence)\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu_score = sentence_bleu([reference_tokens], generated_tokens)\n",
        "print(\"Translation in Hindi:\", generated_translation)\n",
        "print(\"Python Translated Reference:\", python_translated_sentence)\n",
        "print(\"BLEU Score:\", bleu_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jioFfEWljUC",
        "outputId": "240ee8fd-0ee5-460a-beb4-ccd37448eaf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence in English to translate to Hindi: the jury deliberated on charges of the criminal act of deliberately setting fire to property . led to extensive the name for anything which can be owned .'\n",
            "Translation in Hindi: जौरी ने जानबूझकर संपत्ति पर आग लगाने के अपराध के आरोपों पर विचार-विमर्श किया. किसी भी संपत्ति के लिए विस्तृत नाम बनाने के लिए प्रेरित किया. '\n",
            "Python Translated Reference: जूरी ने जानबूझकर संपत्ति में आग लगाने के आपराधिक कृत्य के आरोपों पर विचार-विमर्श किया। \n",
            "BLEU Score: 0.14887309680192354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_text = input(\"Enter a sentence in English to translate to Hindi: \")\n",
        "generated_translation = translate_to_hindi(user_text)\n",
        "\n",
        "# Assuming `python_translated_sentence` is the reference translation from EngtoHindi library\n",
        "trans = EngtoHindi(message=user_text)\n",
        "python_translated_sentence = trans.convert  # Reference translation\n",
        "\n",
        "# Tokenize the generated and reference translations\n",
        "generated_tokens = word_tokenize(generated_translation)\n",
        "reference_tokens = word_tokenize(python_translated_sentence)\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu_score = sentence_bleu([reference_tokens], generated_tokens)\n",
        "print(\"Translation in Hindi:\", generated_translation)\n",
        "print(\"Python Translated Reference:\", python_translated_sentence)\n",
        "print(\"BLEU Score:\", bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJEAFrI-mKPU",
        "outputId": "1a6f871d-9f9f-45f0-ba14-6349e128f83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence in English to translate to Hindi: The (the criminal act of deliberately setting fire to property.) led to extensive (the name for anything which can be owned.) damage .<n>The defendant 's legal team argued for an (the court's decision that a person is innocent of the crime they were charged with).\n",
            "Translation in Hindi: प्रतिवादी के कानूनी दल ने एक (न्यायालय के निर्णय के लिए तर्क दिया कि कोई व्यक्ति उन अपराधों से निर्दोष है जिन पर वह आरोपित किया गया था) के लिए तर्क दिया।\n",
            "Python Translated Reference: (जानबूझकर संपत्ति में आग लगाने का आपराधिक कृत्य) से व्यापक क्षति हुई (किसी भी चीज़ का नाम जिसका स्वामित्व हो सकता है।) प्रतिवादी की कानूनी टीम ने अदालत के फैसले के लिए तर्क दिया कि एक व्यक्ति निर्दोष है \n",
            "BLEU Score: 0.11059204097669541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5PzDZGNujIbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KicLaJYTfDvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m_-a9cSefRbG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}